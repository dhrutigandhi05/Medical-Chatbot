{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6acc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428095f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir(\"OneDrive - Carleton University\\Medical-Chatbot\")\n",
    "# %pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1162e9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac90dc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract text from pdfs\n",
    "def load_pdf_files(data):\n",
    "    loader = DirectoryLoader(\n",
    "        data,\n",
    "        glob=\"*.pdf\",\n",
    "        loader_cls=PyPDFLoader\n",
    "    )\n",
    "    \n",
    "    docs = loader.load()\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a123a1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf_files(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113e5390",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd3be73",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5362be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter function\n",
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "\n",
    "def filter_to_minimal_docs(docs: List[Document]) -> List[Document]:\n",
    "    minimal_docs: List[Document] = []\n",
    "    \n",
    "    # iterate through each document and get the content and source metadata\n",
    "    for doc in docs:\n",
    "        src = doc.metadata.get(\"source\")\n",
    "        minimal_docs.append(\n",
    "            Document(\n",
    "                page_content=doc.page_content,\n",
    "                metadata={\"source\": src}\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return minimal_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab87753e",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimal_docs = filter_to_minimal_docs(extracted_data)\n",
    "minimal_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8a0fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunking the documents\n",
    "def chunk_docs(minimal_docs):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500, # 500 characters = 1 chunk\n",
    "        chunk_overlap=20, # 20 characters overlap between chunks\n",
    "    )\n",
    "\n",
    "    chunks = splitter.split_documents(minimal_docs)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a486198",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = chunk_docs(minimal_docs)\n",
    "print(\"Num of chunks:\", len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0883ba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0c43cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhrut\\AppData\\Local\\Temp\\ipykernel_27140\\3691234583.py:6: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n",
      "c:\\Users\\dhrut\\anaconda3\\envs\\medchatbot\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# embedding model\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "def create_embedding_model():\n",
    "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=model_name,\n",
    "    )\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "embedding = create_embedding_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "292a9423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a661126e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.08429646492004395,\n",
       " 0.05795375257730484,\n",
       " 0.004493334796279669,\n",
       " 0.10582110285758972,\n",
       " 0.007083463482558727,\n",
       " -0.017844678834080696,\n",
       " -0.016888096928596497,\n",
       " -0.015228349715471268,\n",
       " 0.040473055094480515,\n",
       " 0.03342251107096672,\n",
       " 0.10432768613100052,\n",
       " -0.047035831958055496,\n",
       " 0.006884740665555,\n",
       " 0.04101800173521042,\n",
       " 0.01871195249259472,\n",
       " -0.04149232804775238,\n",
       " 0.023647429421544075,\n",
       " -0.05650181323289871,\n",
       " -0.033696215599775314,\n",
       " 0.05099101364612579,\n",
       " 0.06930329650640488,\n",
       " 0.054784249514341354,\n",
       " -0.009788368828594685,\n",
       " 0.023697199299931526,\n",
       " 0.019996512681245804,\n",
       " 0.009717293083667755,\n",
       " -0.05889919772744179,\n",
       " 0.007307454943656921,\n",
       " 0.04702645167708397,\n",
       " -0.004510104190558195,\n",
       " -0.055799711495637894,\n",
       " -0.004159437958151102,\n",
       " 0.06475706398487091,\n",
       " 0.04807630926370621,\n",
       " 0.017020801082253456,\n",
       " -0.0031833855900913477,\n",
       " 0.05740238353610039,\n",
       " 0.03523186966776848,\n",
       " -0.0058838683180511,\n",
       " 0.014832884073257446,\n",
       " 0.011576333083212376,\n",
       " -0.10748078674077988,\n",
       " 0.01910419389605522,\n",
       " 0.02208571694791317,\n",
       " 0.01086457446217537,\n",
       " 0.0037819782737642527,\n",
       " -0.03194037079811096,\n",
       " 0.01072779018431902,\n",
       " -0.004842301364988089,\n",
       " -0.028336212038993835,\n",
       " -0.05257357284426689,\n",
       " -0.07058685272932053,\n",
       " -0.057555828243494034,\n",
       " -0.013632851652801037,\n",
       " 0.00568217970430851,\n",
       " 0.023074597120285034,\n",
       " 0.03569774329662323,\n",
       " 0.014998394064605236,\n",
       " 0.049742743372917175,\n",
       " 0.04262828826904297,\n",
       " -0.034588880836963654,\n",
       " -0.024360043928027153,\n",
       " -0.07152240723371506,\n",
       " 0.08312476426362991,\n",
       " 0.14891894161701202,\n",
       " 0.054018013179302216,\n",
       " -0.0413382388651371,\n",
       " -0.0898984894156456,\n",
       " -0.044525325298309326,\n",
       " 0.014739160425961018,\n",
       " 0.022311871871352196,\n",
       " 0.019573595374822617,\n",
       " 0.043633926659822464,\n",
       " 0.009812230244278908,\n",
       " -0.00380728323943913,\n",
       " -0.014992852695286274,\n",
       " -0.0006991563714109361,\n",
       " -0.11284737288951874,\n",
       " 0.12384183704853058,\n",
       " 0.05555814132094383,\n",
       " -0.08891021460294724,\n",
       " -0.07885009050369263,\n",
       " -0.01689327321946621,\n",
       " 0.04597761854529381,\n",
       " -0.008726944215595722,\n",
       " -0.058138407766819,\n",
       " 0.07659010589122772,\n",
       " -0.03432249650359154,\n",
       " -0.07924256473779678,\n",
       " 0.021766183897852898,\n",
       " -0.03424961864948273,\n",
       " -0.026446733623743057,\n",
       " 0.005298122763633728,\n",
       " 0.004527377896010876,\n",
       " -0.051017988473176956,\n",
       " -0.016586244106292725,\n",
       " -0.08304513245820999,\n",
       " -0.002371344482526183,\n",
       " -0.0011133101070299745,\n",
       " 0.043059442192316055,\n",
       " 0.004377926699817181,\n",
       " 0.02549912966787815,\n",
       " 0.007468871772289276,\n",
       " 0.06316962838172913,\n",
       " -0.09805840998888016,\n",
       " -0.08793117851018906,\n",
       " 0.00035317131550982594,\n",
       " -0.057669926434755325,\n",
       " 0.020637348294258118,\n",
       " -0.007735337130725384,\n",
       " -0.03064650297164917,\n",
       " -0.0020989892072975636,\n",
       " 0.05955915153026581,\n",
       " 0.019579749554395676,\n",
       " -0.012472529895603657,\n",
       " 0.009707980789244175,\n",
       " -0.1231774240732193,\n",
       " 0.025990936905145645,\n",
       " -0.01577664539217949,\n",
       " 0.04943506792187691,\n",
       " 0.061541199684143066,\n",
       " 0.07830119132995605,\n",
       " -0.029691437259316444,\n",
       " -0.013186508789658546,\n",
       " -0.062351010739803314,\n",
       " -0.08068269491195679,\n",
       " 0.05496545508503914,\n",
       " -6.962590425822661e-33,\n",
       " -0.025842078030109406,\n",
       " -0.06677987426519394,\n",
       " 0.04351392388343811,\n",
       " 0.07399920374155045,\n",
       " 0.01025924738496542,\n",
       " -0.0244536604732275,\n",
       " -0.021248869597911835,\n",
       " 0.06839420646429062,\n",
       " -0.022924872115254402,\n",
       " -7.915330934338272e-05,\n",
       " -0.0025823381729424,\n",
       " -0.09488371759653091,\n",
       " 0.013310877606272697,\n",
       " 0.04063046723604202,\n",
       " 0.08562179654836655,\n",
       " 0.09818195551633835,\n",
       " -0.0766807496547699,\n",
       " 0.06953238695859909,\n",
       " -0.04674630984663963,\n",
       " 0.05553460866212845,\n",
       " -0.03531914949417114,\n",
       " 0.038122352212667465,\n",
       " -0.018466824665665627,\n",
       " -0.0654691755771637,\n",
       " -0.09128424525260925,\n",
       " -0.11191485822200775,\n",
       " 0.002208017511293292,\n",
       " 0.00841345451772213,\n",
       " -0.047066524624824524,\n",
       " 0.02035696431994438,\n",
       " 0.01065555214881897,\n",
       " 0.026104316115379333,\n",
       " -0.02678087167441845,\n",
       " 0.06011931225657463,\n",
       " 0.020277518779039383,\n",
       " 0.016695216298103333,\n",
       " 0.035287972539663315,\n",
       " -0.07817286252975464,\n",
       " -0.02583703026175499,\n",
       " 0.010249652899801731,\n",
       " -0.06147533655166626,\n",
       " -0.028475871309638023,\n",
       " -0.010275817476212978,\n",
       " 0.012673893012106419,\n",
       " 0.09546967595815659,\n",
       " -0.01214388757944107,\n",
       " -0.014245819300413132,\n",
       " -0.026192456483840942,\n",
       " -0.006299291737377644,\n",
       " 0.022196687757968903,\n",
       " -0.02608403190970421,\n",
       " 0.04394347965717316,\n",
       " 0.07364541292190552,\n",
       " -0.033389341086149216,\n",
       " 0.0321776457130909,\n",
       " 0.06466919183731079,\n",
       " 0.04931938275694847,\n",
       " -0.010532060638070107,\n",
       " -0.03472786396741867,\n",
       " 0.06571028381586075,\n",
       " -0.02722322568297386,\n",
       " 0.06035558134317398,\n",
       " -0.06002897769212723,\n",
       " 0.056270893663167953,\n",
       " 0.0068089221604168415,\n",
       " 0.018710661679506302,\n",
       " -0.04291004315018654,\n",
       " -0.0409596785902977,\n",
       " 0.05299200117588043,\n",
       " 0.033094458281993866,\n",
       " -0.015546543523669243,\n",
       " -0.07298672944307327,\n",
       " -0.05088841915130615,\n",
       " 0.06311015039682388,\n",
       " -0.01297728531062603,\n",
       " -0.07079783082008362,\n",
       " 0.014870570041239262,\n",
       " 0.03425676003098488,\n",
       " 0.008295005187392235,\n",
       " 0.0097907530143857,\n",
       " 0.02341691218316555,\n",
       " -0.11210940778255463,\n",
       " 0.02823590487241745,\n",
       " -0.052784983068704605,\n",
       " -0.09382615983486176,\n",
       " -0.0005617879214696586,\n",
       " -0.019316291436553,\n",
       " -0.08856189996004105,\n",
       " 0.024456290528178215,\n",
       " -0.024815497919917107,\n",
       " 0.012973331846296787,\n",
       " 0.02320919558405876,\n",
       " 0.03923256695270538,\n",
       " -0.033732037991285324,\n",
       " 0.022117258980870247,\n",
       " 2.897062949280138e-33,\n",
       " -0.03425547108054161,\n",
       " 0.06554900854825974,\n",
       " -0.07177571207284927,\n",
       " 0.08654050529003143,\n",
       " 0.0871615931391716,\n",
       " -0.030142057687044144,\n",
       " 0.06583679467439651,\n",
       " -0.033409975469112396,\n",
       " -0.03749047592282295,\n",
       " 0.13489797711372375,\n",
       " -0.04510383680462837,\n",
       " 0.033019233494997025,\n",
       " -0.0042403694242239,\n",
       " -0.022089529782533646,\n",
       " 0.03936818987131119,\n",
       " 0.011286133900284767,\n",
       " 0.010816485621035099,\n",
       " -0.049026716500520706,\n",
       " -0.018285512924194336,\n",
       " -0.02391713485121727,\n",
       " -0.058630552142858505,\n",
       " 0.12643468379974365,\n",
       " 0.017078444361686707,\n",
       " 0.10173556953668594,\n",
       " -0.041665658354759216,\n",
       " 0.003737666876986623,\n",
       " 0.014300950802862644,\n",
       " -0.06777306646108627,\n",
       " -0.0740957111120224,\n",
       " 0.020246457308530807,\n",
       " 0.02114488184452057,\n",
       " -0.033830564469099045,\n",
       " -0.09985559433698654,\n",
       " -0.008472183719277382,\n",
       " 0.010729018598794937,\n",
       " 0.008691268041729927,\n",
       " 0.10240782052278519,\n",
       " -0.07643356174230576,\n",
       " -0.05176011100411415,\n",
       " 0.030973147600889206,\n",
       " 0.004117773845791817,\n",
       " 0.027470888569951057,\n",
       " 0.06673252582550049,\n",
       " 0.14349894225597382,\n",
       " 0.013602337799966335,\n",
       " 0.012040999718010426,\n",
       " -0.02445259504020214,\n",
       " -0.14091478288173676,\n",
       " -0.04332244023680687,\n",
       " 0.04307663068175316,\n",
       " -0.05558881163597107,\n",
       " 0.02399279735982418,\n",
       " -0.012689565308392048,\n",
       " 0.01733713410794735,\n",
       " -0.06776981055736542,\n",
       " 0.011357974261045456,\n",
       " -0.031879179179668427,\n",
       " -0.029640497639775276,\n",
       " -0.025059683248400688,\n",
       " -0.0022674305364489555,\n",
       " -0.09762751311063766,\n",
       " 0.060350123792886734,\n",
       " 0.006841600872576237,\n",
       " 0.03214393928647041,\n",
       " 0.02294873632490635,\n",
       " -0.0713614672422409,\n",
       " -0.07719399034976959,\n",
       " 0.09534020721912384,\n",
       " 0.026547806337475777,\n",
       " -0.060325250029563904,\n",
       " 0.10291105508804321,\n",
       " 0.029590891674160957,\n",
       " -0.1088823676109314,\n",
       " -0.024806538596749306,\n",
       " -0.033233392983675,\n",
       " -0.08235333114862442,\n",
       " -0.08177332580089569,\n",
       " -0.01764236018061638,\n",
       " -0.019313722848892212,\n",
       " -0.08298197388648987,\n",
       " -0.018056144937872887,\n",
       " -0.05327998846769333,\n",
       " 0.004699525889009237,\n",
       " 0.01525804027915001,\n",
       " -0.08144970238208771,\n",
       " 0.0385303869843483,\n",
       " -0.004425995983183384,\n",
       " -0.027970854192972183,\n",
       " -0.010203558020293713,\n",
       " 0.044200025498867035,\n",
       " -0.01693393476307392,\n",
       " -0.055132150650024414,\n",
       " 0.039740584790706635,\n",
       " -0.02304832823574543,\n",
       " -0.026844890788197517,\n",
       " -1.9580529198037766e-08,\n",
       " -0.01867200806736946,\n",
       " -0.01171102374792099,\n",
       " 0.014648012816905975,\n",
       " 0.0066586025059223175,\n",
       " 0.0007370951352640986,\n",
       " 0.06258219480514526,\n",
       " 0.06776582449674606,\n",
       " -0.005954991560429335,\n",
       " -0.030519645661115646,\n",
       " -0.0008199920994229615,\n",
       " 0.06429591029882431,\n",
       " 0.06641700118780136,\n",
       " -0.09795111417770386,\n",
       " -8.533465916116256e-06,\n",
       " 0.06032374128699303,\n",
       " -0.02740229107439518,\n",
       " 0.0242515429854393,\n",
       " -0.021256422623991966,\n",
       " -0.002669545356184244,\n",
       " 0.08429719507694244,\n",
       " -0.048472192138433456,\n",
       " 0.04775247350335121,\n",
       " 0.013190941885113716,\n",
       " 0.04648696631193161,\n",
       " -0.00297927507199347,\n",
       " 0.044155605137348175,\n",
       " 0.09958913177251816,\n",
       " 0.06427279859781265,\n",
       " 0.0033607743680477142,\n",
       " 0.04497558996081352,\n",
       " 0.11025182902812958,\n",
       " 0.06426677852869034,\n",
       " -0.03681514412164688,\n",
       " -0.03154785558581352,\n",
       " -0.014766694977879524,\n",
       " 0.08226469159126282,\n",
       " 0.05671500042080879,\n",
       " -0.0649479404091835,\n",
       " 0.02308061718940735,\n",
       " 0.019234739243984222,\n",
       " -0.05154435336589813,\n",
       " 0.07222791016101837,\n",
       " -0.014392138458788395,\n",
       " 0.07818154245615005,\n",
       " -0.011162650771439075,\n",
       " -0.049568288028240204,\n",
       " -0.03159089386463165,\n",
       " -0.029547549784183502,\n",
       " -0.015165124088525772,\n",
       " -0.0539255253970623,\n",
       " -0.00885928887873888,\n",
       " 0.02106480859220028,\n",
       " 0.04502761363983154,\n",
       " -0.022881189361214638,\n",
       " 0.02681281603872776,\n",
       " -0.03306547552347183,\n",
       " -0.0034950552508234978,\n",
       " -0.030414914712309837,\n",
       " -0.07156666368246078,\n",
       " 0.023295696824789047,\n",
       " 0.08976894617080688,\n",
       " 0.004571126773953438,\n",
       " 0.08188025653362274,\n",
       " -0.09904708713293076]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the embedding model\n",
    "vector = embedding.embed_query(\"This is a test sentence.\") # embedding vector for the test sentence\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c42f45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of embedding vector: 384\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of embedding vector:\", len(vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e337d22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "667c4ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "pinecone_api_key = PINECONE_API_KEY\n",
    "pc = Pinecone(api_key=pinecone_api_key) # initialize pinecone client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d9cd20f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone.pinecone.Pinecone at 0x1e5ffcf7c40>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a507804a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"medical-chatbot\"\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50d0d23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create pinecone index\n",
    "# from pinecone import ServerlessSpec\n",
    "\n",
    "# index_name = \"medical-chatbot\"\n",
    "\n",
    "# if not pc.has_index(index_name):\n",
    "#     pc.create_index(\n",
    "#         name=index_name,\n",
    "#         dimension=384, # higher dimension = more accurate embeddings and more info\n",
    "#         metric=\"cosine\",\n",
    "#         spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "#     )\n",
    "\n",
    "# index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd1b5bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use langchain pinecone to create vector store\n",
    "# from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "# docsearch = PineconeVectorStore.from_documents(\n",
    "#     documents=chunks,\n",
    "#     embedding=embedding,\n",
    "#     index_name=index_name\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d9fe075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load exsisting pinecone index\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    embedding=embedding,\n",
    "    index_name=index_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3a3ff6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3}) # retrieve top 3 similar/relevant responses from the knowledge base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38738e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='46b1b2e0-d0e8-4446-bebe-db5da8f40862', metadata={'source': 'data\\\\Medical_book.pdf'}, page_content='GALE ENCYCLOPEDIA OF MEDICINE 226\\nAcne\\nGEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 26'),\n",
       " Document(id='dbc9c6d0-0078-415b-b309-0205adc2a73f', metadata={'source': 'data\\\\Medical_book.pdf'}, page_content='GALE ENCYCLOPEDIA OF MEDICINE 2 25\\nAcne\\nAcne vulgaris affecting a womanâ€™s face. Acne is the general\\nname given to a skin disorder in which the sebaceous\\nglands become inflamed. (Photograph by Biophoto Associ-\\nates, Photo Researchers, Inc. Reproduced by permission.)\\nGEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 25'),\n",
       " Document(id='d90783e6-9670-4452-9424-74d9d158a090', metadata={'source': 'data\\\\Medical_book.pdf'}, page_content='Acidosis see Respiratory acidosis; Renal\\ntubular acidosis; Metabolic acidosis\\nAcne\\nDefinition\\nAcne is a common skin disease characterized by\\npimples on the face, chest, and back. It occurs when the\\npores of the skin become clogged with oil, dead skin\\ncells, and bacteria.\\nDescription\\nAcne vulgaris, the medical term for common acne, is\\nthe most common skin disease. It affects nearly 17 million\\npeople in the United States. While acne can arise at any')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the retriever\n",
    "retrieved_docs = retriever.invoke(\"What is Acne?\")\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f39a1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatModel = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cda4ecbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c67b744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define custom prompt template\n",
    "system_prompts = (\n",
    "    \"You are a medical assistant for question-answering tasks.\"\n",
    "    \"Use the following pieces of retrieved context to answer the question.\"\n",
    "    \"If you don't know the answer, just say that you don't know, don't try to make up an answer.\"\n",
    "    \"Use three sentences maximum to answer the question and keep it concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "# create prompt template\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompts),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7686035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answering_chain = create_stuff_documents_chain(chatModel, prompt) # create a chain that stuffs all retrieved documents into the prompt \n",
    "rag_chain = create_retrieval_chain(retriever, question_answering_chain) # create a rag chain using the retriever and the question answering chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abd2853",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
